{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('../problems/problem_1/train/train_label.csv')\n",
    "train_profile = pd.read_csv('../problems/problem_1/train/train_profile.csv')\n",
    "test_profile = pd.read_csv('../problems/problem_1/B/test_profile_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0.129980\n",
    "train = train_profile.merge(train_label, 'left', '用户标识')\n",
    "test = test_profile.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_time_min = pd.read_hdf('./feats_v6/credit_time_min.h5', key='data')  # 0.251811\n",
    "credit_time_max = pd.read_hdf('./feats_v6/credit_time_max.h5', key='data')  # 0.350979\n",
    "credit_time_std = pd.read_hdf('./feats_v6/credit_time_std.h5', key='data')  # 0.351767\n",
    "credit_time_skew = pd.read_hdf('./feats_v6/credit_time_skew.h5', key='data')  # 0.359765 BUG\n",
    "credit_time_mm2 = pd.read_hdf('./feats_v6/credit_time_mm2.h5', key='data')  # 0.359878\n",
    "credit_time_gap = pd.read_hdf('./feats_v6/credit_time_gap.h5', key='data') # 0.359967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankstat_cnt = pd.read_hdf('./feats_v6/bankstat_cnt.h5', key='data') # 0.369053\n",
    "bankstat_time = pd.read_hdf('./feats_v6/bankstat_time.h5', key='data') # 0.374102\n",
    "bankstat_time2 = pd.read_hdf('./feats_v6/bankstat_time2.h5', key='data') # 0.374510\n",
    "bankstat_amt2 = pd.read_hdf('./feats_v6/bankstat_amt2.h5', key='data') # 0.378059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_cnt = pd.read_hdf('./feats_v6/behavior_cnt.h5', key='data') # 0.393364\n",
    "behavior_cnt2 = pd.read_hdf('./feats_v6/behavior_cnt2.h5', key='data') # 0.401803\n",
    "behavior_cnt3 = pd.read_hdf('./feats_v6/behavior_cnt3.h5', key='data') # 0.450277\n",
    "behavior_cnt4 = pd.read_hdf('./feats_v6/behavior_cnt4.h5', key='data') # 0.463653 (all) 0.463548 (0.9)\n",
    "behavior_time = pd.read_hdf('./feats_v6/behavior_time.h5', key='data') # 0.466040 (300) 0.466140 (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上期账单金额\n",
    "creditbill_amt1_sum = pd.read_hdf('./feats_v6/creditbill_amt1_sum.h5', key='data') # 0.466829\n",
    "# 上期还款金额\n",
    "creditbill_amt2_mean = pd.read_hdf('./feats_v6/creditbill_amt2_mean.h5', key='data') # 0.471863\n",
    "creditbill_amt2_min = pd.read_hdf('./feats_v6/creditbill_amt2_min.h5', key='data') # 0.475831\n",
    "# 本期账单余额\n",
    "creditbill_amt3_max = pd.read_hdf('./feats_v6/creditbill_amt3_max.h5', key='data') # 0.475847\n",
    "creditbill_amt3_std = pd.read_hdf('./feats_v6/creditbill_amt3_std.h5', key='data') # 0.476084\n",
    "# 信用卡额度\n",
    "creditbill_amt4_mean = pd.read_hdf('./feats_v6/creditbill_amt4_mean.h5', key='data') # 0.478530\n",
    "creditbill_amt4_max = pd.read_hdf('./feats_v6/creditbill_amt4_max.h5', key='data') # 0.479430\n",
    "creditbill_amt4_skew = pd.read_hdf('./feats_v6/creditbill_amt4_skew.h5', key='data') # 0.480112\n",
    "# 上期账单金额-上期还款金额\n",
    "creditbill_amt5_mean = pd.read_hdf('./feats_v6/creditbill_amt5_mean.h5', key='data') # 0.480179\n",
    "creditbill_amt5_min = pd.read_hdf('./feats_v6/creditbill_amt5_min.h5', key='data') # 0.481522\n",
    "creditbill_amt5_max = pd.read_hdf('./feats_v6/creditbill_amt5_max.h5', key='data') # 0.485155\n",
    "creditbill_amt5_std = pd.read_hdf('./feats_v6/creditbill_amt5_std.h5', key='data') # 0.486459\n",
    "creditbill_amt5_skew = pd.read_hdf('./feats_v6/creditbill_amt5_skew.h5', key='data') # 0.486882\n",
    "# 上期账单金额-信用卡额度\n",
    "creditbill_amt7_max = pd.read_hdf('./feats_v6/creditbill_amt7_max.h5', key='data') # 0.488431\n",
    "creditbill_amt7_std = pd.read_hdf('./feats_v6/creditbill_amt7_std.h5', key='data') # 0.488563\n",
    "creditbill_amt7_sum = pd.read_hdf('./feats_v6/creditbill_amt7_sum.h5', key='data')# 0.489102\n",
    "creditbill_amt7_skew = pd.read_hdf('./feats_v6/creditbill_amt7_skew.h5', key='data') # 0.491199\n",
    "# 本期账单余额-信用卡额度\n",
    "creditbill_amt10_min = pd.read_hdf('./feats_v6/creditbill_amt10_min.h5', key='data') # 0.492479\n",
    "creditbill_amt10_mean = pd.read_hdf('./feats_v6/creditbill_amt10_mean.h5', key='data') # 0.492547 (300) # 0.493882 (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_time_diff = pd.read_hdf('./feats_v6/credit_time_diff.h5', key='data') # 0.493540 (300) 0.496487 (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_dfs = [credit_time_min, credit_time_max, credit_time_std, credit_time_mm2, credit_time_gap, \n",
    "                bankstat_cnt, bankstat_time, bankstat_time2, bankstat_amt2,\n",
    "                behavior_cnt, behavior_cnt2, behavior_cnt3, behavior_cnt4, behavior_time,\n",
    "                creditbill_amt1_sum, \n",
    "                creditbill_amt2_mean, creditbill_amt2_min, \n",
    "                creditbill_amt3_max, creditbill_amt3_std,\n",
    "                creditbill_amt4_mean, creditbill_amt4_max, creditbill_amt4_skew,\n",
    "                creditbill_amt5_mean, creditbill_amt5_min, creditbill_amt5_max, creditbill_amt5_std, creditbill_amt5_skew,\n",
    "                creditbill_amt7_max, creditbill_amt7_std, creditbill_amt7_sum, creditbill_amt7_skew,\n",
    "                creditbill_amt10_min, creditbill_amt10_mean, \n",
    "                credit_time_diff] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in all_feat_dfs:\n",
    "    train = train.merge(df, 'left', '用户标识')\n",
    "    test = test.merge(df, 'left', '用户标识')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_feat = [f for f in test.columns if f not in ['用户标识'] + list(drop_feat)]\n",
    "print(len(used_feat))\n",
    "print(used_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[used_feat].reset_index(drop=True)\n",
    "train_y = train['标签'].reset_index(drop=True)\n",
    "test_x = test[used_feat].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks(labels, preds):\n",
    "    fpr,tpr,thresholds = roc_curve(y_true=labels, y_score=preds)\n",
    "    return 'ks', max(tpr-fpr), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbs = []\n",
    "has_saved = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((test_x.shape[0], 2))\n",
    "scores = []\n",
    "\n",
    "imp = pd.DataFrame()\n",
    "imp['feat'] = used_feat\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for index, (tr_idx, va_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "    print('*' * 30)\n",
    "    X_train, y_train, X_valid, y_valid = train_x.iloc[tr_idx], train_y.iloc[tr_idx], train_x.iloc[va_idx], train_y.iloc[va_idx]\n",
    "    \n",
    "    eval_set = [(X_valid, y_valid)]\n",
    "    if not has_saved: \n",
    "        lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=64, reg_alpha=0, reg_lambda=1.9, max_bin=64, \n",
    "                                    max_depth=-1, n_estimators=10000, objective='binary', metrics='None', \n",
    "                                    bagging_fraction=0.8, is_unbalance=False, bagging_freq=5, min_child_samples=80, \n",
    "                                    feature_fraction=0.8, learning_rate=0.01, random_state=42, n_jobs=8,\n",
    "                                    )\n",
    "#         lgb_model.set_params(**params)\n",
    "        lgb_model.fit(X_train, y_train, eval_set=eval_set, eval_metric=ks ,verbose=300, early_stopping_rounds=1000)\n",
    "        with open('./models/fold%d_lgb.mdl' % index, 'wb') as file:\n",
    "            pickle.dump(lgb_model, file)\n",
    "    else:\n",
    "        with open('./models/fold%d_lgb.mdl' % index, 'rb') as file:\n",
    "            lgb_model = pickle.load(file)\n",
    "    \n",
    "    imp['score%d' % (index+1)] = lgb_model.feature_importances_\n",
    "    \n",
    "    score = lgb_model.best_score_['valid_0']['ks']\n",
    "    scores.append(score)\n",
    "    print('fold %d round %d : score: %.6f | mean score %.6f' % (index+1, lgb_model.best_iteration_, score,np.mean(scores))) \n",
    "    preds += lgb_model.predict_proba(test_x)  \n",
    "    \n",
    "    lgbs.append(lgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp['score'] = imp['score1'] + imp['score2'] + imp['score3'] + imp['score4'] + imp['score5'] \n",
    "imp.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['客户号'] = test_profile['用户标识'] \n",
    "result['违约概率'] = preds[:, 1]/5\n",
    "print(len(result))\n",
    "display(result.head())\n",
    "result.to_csv('./out/upload_B501785.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
